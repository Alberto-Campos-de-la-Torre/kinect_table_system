# Kinect Table System - Sistema de Reconocimiento de Objetos Interactivo

![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-en%20desarrollo-yellow)

## ğŸ“‹ DescripciÃ³n

Sistema interactivo de reconocimiento de objetos y gestos utilizando Kinect Xbox 360 sobre una mesa-pantalla (televisor horizontal). El sistema detecta objetos en tiempo real, muestra sus siluetas y caracterÃ­sticas, y permite interacciÃ³n mediante gestos manuales.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¯ **DetecciÃ³n de objetos en tiempo real** con YOLO
- ğŸ‘‹ **Reconocimiento de gestos manuales** con MediaPipe
- ğŸ“Š **VisualizaciÃ³n de caracterÃ­sticas** de objetos detectados
- ğŸ–¥ï¸ **Interfaz visual interactiva** en mesa-pantalla
- ğŸ”„ **Procesamiento 3D** con datos de profundidad del Kinect
- âš¡ **Rendimiento optimizado** (30+ FPS)

## ğŸ› ï¸ Requerimientos

### Hardware
- Kinect para Xbox 360 (modelo 1414 o 1473)
- Adaptador de corriente y USB para Kinect
- Televisor/Monitor 40-55" (montado horizontalmente)
- PC con:
  - CPU: Intel i5 6ta gen o AMD Ryzen 5+
  - RAM: 8GB mÃ­nimo (16GB recomendado)
  - GPU: NVIDIA GTX 1050+ (opcional pero recomendado)
  - USB 3.0

### Software
- Python 3.8 - 3.10
- Windows 10/11 o Ubuntu 20.04+
- Kinect for Windows SDK 2.0 (Windows) o libfreenect (Linux)
- CUDA Toolkit (opcional, para aceleraciÃ³n GPU)

## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/kinect_table_system.git
cd kinect_table_system
```

### 2. Crear entorno virtual
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Instalar drivers del Kinect

#### Windows:
- Descargar e instalar [Kinect for Windows SDK 2.0](https://www.microsoft.com/en-us/download/details.aspx?id=44561)

#### Linux:
```bash
sudo apt-get install libfreenect-dev
sudo apt-get install freenect
```

### 5. Descargar modelos pre-entrenados
```bash
python scripts/download_models.py
```

## ğŸ“– Uso BÃ¡sico

### Ejecutar el sistema completo
```bash
python main.py
```

### Ejecutar solo captura del Kinect (prueba)
```bash
python modules/kinect_capture.py
```

### Ejecutar calibraciÃ³n
```bash
python scripts/calibrate.py
```

### Ejecutar modo demo
```bash
python main.py --demo
```

## ğŸ“ Estructura del Proyecto

```
kinect_table_system/
â”œâ”€â”€ main.py                      # Punto de entrada principal
â”œâ”€â”€ config.py                    # ConfiguraciÃ³n global
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ README.md                    # Este archivo
â”‚
â”œâ”€â”€ modules/                     # MÃ³dulos principales
â”‚   â”œâ”€â”€ kinect_capture.py       # Captura de datos del Kinect
â”‚   â”œâ”€â”€ preprocessing.py        # Preprocesamiento de imÃ¡genes
â”‚   â”œâ”€â”€ calibration.py          # CalibraciÃ³n de cÃ¡maras
â”‚   â”œâ”€â”€ segmentation.py         # SegmentaciÃ³n de objetos
â”‚   â”œâ”€â”€ object_detection.py     # DetecciÃ³n con YOLO
â”‚   â”œâ”€â”€ feature_extraction.py   # ExtracciÃ³n de caracterÃ­sticas
â”‚   â”œâ”€â”€ gesture_recognition.py  # Reconocimiento de gestos
â”‚   â”œâ”€â”€ hand_tracking.py        # Tracking de manos
â”‚   â””â”€â”€ visualization.py        # Renderizado e interfaz
â”‚
â”œâ”€â”€ models/                      # Modelos de ML
â”‚   â””â”€â”€ README.md               # Instrucciones de modelos
â”‚
â”œâ”€â”€ data/                        # Datos del sistema
â”‚   â”œâ”€â”€ calibration/            # Datos de calibraciÃ³n
â”‚   â”œâ”€â”€ objects_db/             # Base de datos de objetos
â”‚   â””â”€â”€ templates/              # Templates de gestos
â”‚
â”œâ”€â”€ utils/                       # Utilidades
â”‚   â”œâ”€â”€ geometry.py             # Funciones geomÃ©tricas
â”‚   â”œâ”€â”€ image_processing.py     # Procesamiento de imÃ¡genes
â”‚   â””â”€â”€ logger.py               # Sistema de logging
â”‚
â”œâ”€â”€ tests/                       # Tests unitarios
â”‚   â”œâ”€â”€ test_capture.py
â”‚   â”œâ”€â”€ test_detection.py
â”‚   â””â”€â”€ test_gestures.py
â”‚
â”œâ”€â”€ scripts/                     # Scripts auxiliares
â”‚   â”œâ”€â”€ download_models.py      # Descargar modelos
â”‚   â”œâ”€â”€ calibrate.py            # Script de calibraciÃ³n
â”‚   â””â”€â”€ benchmark.py            # Pruebas de rendimiento
â”‚
â””â”€â”€ docs/                        # DocumentaciÃ³n adicional
    â”œâ”€â”€ INSTALLATION.md         # GuÃ­a de instalaciÃ³n detallada
    â”œâ”€â”€ API.md                  # DocumentaciÃ³n de API
    â””â”€â”€ TROUBLESHOOTING.md      # SoluciÃ³n de problemas
```

## ğŸ® Gestos Soportados

| Gesto | AcciÃ³n |
|-------|--------|
| âœ‹ Mano abierta | Seleccionar objeto |
| âœŠ PuÃ±o cerrado | Mover objeto |
| ğŸ‘ Pulgar arriba | Zoom in |
| ğŸ‘ Pulgar abajo | Zoom out |
| ğŸ¤ Pellizco | Rotar objeto |
| ğŸ‘‹ Deslizar | Navegar menÃº |

## ğŸ”§ ConfiguraciÃ³n

El archivo `config.py` contiene todas las configuraciones del sistema:

```python
# Ejemplo de configuraciÃ³n
KINECT_RESOLUTION = (1920, 1080)
DEPTH_RESOLUTION = (512, 424)
FPS_TARGET = 30
DETECTION_CONFIDENCE = 0.5
```

## ğŸ“Š Estado del Proyecto

### Fase Actual: âœ… Fase 1 - ConfiguraciÃ³n Base

- [x] Estructura del repositorio
- [x] ConfiguraciÃ³n de dependencias
- [ ] Captura bÃ¡sica de Kinect
- [ ] VisualizaciÃ³n de streams RGB y profundidad

### PrÃ³ximas Fases:
- [ ] Fase 2: Preprocesamiento y SegmentaciÃ³n
- [ ] Fase 3: Reconocimiento de Objetos
- [ ] Fase 4: Reconocimiento de Gestos
- [ ] Fase 5: Interfaz Visual Avanzada
- [ ] Fase 6: IntegraciÃ³n y Mejoras
- [ ] Fase 7: Pruebas y Refinamiento

## ğŸ¤ Contribuir

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autores

- Tu Nombre - Desarrollo inicial

## ğŸ™ Agradecimientos

- OpenKinect por libfreenect
- Ultralytics por YOLOv5/v8
- Google por MediaPipe
- Comunidad de OpenCV

## ğŸ“§ Contacto

- Email: tu-email@ejemplo.com
- GitHub: [@tu-usuario](https://github.com/tu-usuario)
- LinkedIn: [Tu Perfil](https://linkedin.com/in/tu-perfil)

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de Kinect SDK](https://developer.microsoft.com/en-us/windows/kinect)
- [OpenCV Documentation](https://docs.opencv.org/)
- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [YOLOv5 GitHub](https://github.com/ultralytics/yolov5)

---

â­ Si este proyecto te resulta Ãºtil, considera darle una estrella en GitHub
